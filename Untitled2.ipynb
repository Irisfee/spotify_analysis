{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/packages/miniconda/20190102/envs/anaconda-tensorflow-gpu/lib/python3.6/site-packages/dask/dataframe/utils.py:15: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Fully CNN approach\n",
    "'''\n",
    "import argparse\n",
    "from math import floor, log2\n",
    "from os import fsync, mkdir, path\n",
    "from shutil import rmtree\n",
    "from sys import stdout\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "# from trend_clstr import DTWDistance\n",
    "\n",
    "\n",
    "MEL_BIN = 128\n",
    "FRAME_NUM = 323\n",
    "TAG_SIZE = 50\n",
    "A2V_SIZE = 40\n",
    "DR = 0.25\n",
    "LR = 5e-3\n",
    "LR_DECAY = 0.9\n",
    "TRAIN_SIZE = 0.8  # 80% data for training\n",
    "VAL_SIZE = 0.1\n",
    "TEST_SIZE = 1 - TRAIN_SIZE - VAL_SIZE\n",
    "W = 5\n",
    "TIMESPAN = 60\n",
    "RET_TIMESPAN = 29\n",
    "\n",
    "\n",
    "GPU_USAGE = 0.4\n",
    "\n",
    "\n",
    "def leaky_relu(x, alpha=0.1):\n",
    "    return tf.nn.relu(x) - alpha * tf.nn.relu(-x)\n",
    "\n",
    "\n",
    "NON_LINEAR = leaky_relu\n",
    "\n",
    "\n",
    "def norm(x):\n",
    "    return -1 / np.log10(x)\n",
    "\n",
    "\n",
    "def denorm(x):\n",
    "    x[x < 0.0] = 0.0\n",
    "    return 10 ** (-1 / x)\n",
    "\n",
    "\n",
    "def make_tag_batch(tg, trix, pos, b_size):\n",
    "    ids = trix[pos:pos + b_size]\n",
    "    b_tg = np.take(tg, ids, axis=0)\n",
    "\n",
    "    return b_tg\n",
    "\n",
    "\n",
    "def make_a2v_batch(a2v, trix, pos, b_size):\n",
    "    ids = trix[pos:pos + b_size]\n",
    "    b_a2v = np.take(a2v, ids, axis=0)\n",
    "\n",
    "    return b_a2v\n",
    "\n",
    "\n",
    "def make_batch(feat, pt, trix, pos, b_size):\n",
    "    ids = trix[pos:pos + b_size]\n",
    "    b_f = np.take(feat, ids, axis=0)\n",
    "    b_pt = np.take(pt, ids, axis=0) if pt is not None else None\n",
    "\n",
    "    return b_f, b_pt\n",
    "\n",
    "\n",
    "def make_mt_batch(feat, pt, trd, trix, pos, b_size):\n",
    "    ids = trix[pos:pos + b_size]\n",
    "    b_trd = np.take(trd, ids, axis=0)\n",
    "    b_f, b_pt = make_batch(feat, pt, trix, pos, b_size)\n",
    "    return b_f, b_pt, b_trd\n",
    "\n",
    "\n",
    "def make_mr_batch(feat, pt, ret, trix, pos, b_size):\n",
    "    ids = trix[pos:pos + b_size]\n",
    "    b_ret = np.take(ret, ids, axis=0)\n",
    "    b_f, b_pt = make_batch(feat, pt, trix, pos, b_size)\n",
    "    return b_f, b_pt, b_ret\n",
    "\n",
    "\n",
    "def make_mtr_batch(feat, pt, trd, ret, trix, pos, b_size):\n",
    "    ids = trix[pos:pos + b_size]\n",
    "    b_ret = np.take(ret, ids, axis=0)\n",
    "\n",
    "    b_f, b_pt, b_trd = make_mt_batch(feat, pt, trd, trix, pos, b_size)\n",
    "    return b_f, b_pt, b_trd, b_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard module is not an IPython extension.\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v1.summary' has no attribute 'trace_on'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0da6dea8ed3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mlogits_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emb'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlogits_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.summary' has no attribute 'trace_on'"
     ]
    }
   ],
   "source": [
    "\n",
    "def conv1_128_4_gen(x):\n",
    "    return tf.layers.conv2d(\n",
    "        inputs=x,\n",
    "        filters=32,\n",
    "        kernel_size=[128, 4],\n",
    "        activation=NON_LINEAR)\n",
    "\n",
    "\n",
    "def cnn(x, dr, mode, stt):\n",
    "    # 128*323*1\n",
    "\n",
    "    # 1*320*32\n",
    "    return cnn_body(conv1_128_4_gen(x), dr, mode, stt)\n",
    "\n",
    "\n",
    "def inception_cnn(x, dr, mode, stt):\n",
    "    # 128*323*1\n",
    "\n",
    "    # 1*320*32\n",
    "    conv1_128_4 = conv1_128_4_gen(x)\n",
    "\n",
    "    # 132*327*1\n",
    "    pad1_132_8 = tf.pad(x, [[0, 0], [2, 2], [2, 2], [0, 0]])\n",
    "    # 1*320*16\n",
    "    conv1_132_8 = tf.layers.conv2d(\n",
    "        inputs=pad1_132_8,\n",
    "        filters=16,\n",
    "        kernel_size=[132, 8],\n",
    "        activation=NON_LINEAR)\n",
    "\n",
    "    # 140*335*1\n",
    "    pad1_140_16 = tf.pad(x, [[0, 0], [6, 6], [6, 6], [0, 0]])\n",
    "    # 1*320*16\n",
    "    conv1_140_16 = tf.layers.conv2d(\n",
    "        inputs=pad1_140_16,\n",
    "        filters=16,\n",
    "        kernel_size=[140, 16],\n",
    "        activation=NON_LINEAR)\n",
    "\n",
    "    # 1*320*64\n",
    "    concat = tf.concat([conv1_128_4, conv1_132_8, conv1_140_16], axis=3)\n",
    "    # 1*320*32\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=concat,\n",
    "        filters=32,\n",
    "        kernel_size=[1, 1],\n",
    "        activation=NON_LINEAR)\n",
    "\n",
    "    return cnn_body(conv1, dr, mode, stt)\n",
    "\n",
    "\n",
    "def cnn_body(head, dr, mode, stt):\n",
    "    # 1*320*32\n",
    "\n",
    "    logits_all = {}\n",
    "\n",
    "    # 1*160*32\n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "        inputs=head, pool_size=[1, 2], strides=[1, 2])\n",
    "\n",
    "    # 1*157*64\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[1, 4],\n",
    "        activation=NON_LINEAR)\n",
    "\n",
    "    # 1*78*64\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "        inputs=conv2, pool_size=[1, 2], strides=[1, 2])\n",
    "    drop1 = tf.layers.dropout(\n",
    "        inputs=pool2, rate=dr, training=(mode == learn.ModeKeys.TRAIN))\n",
    "\n",
    "    # 1*78*256\n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=drop1,\n",
    "        filters=256,\n",
    "        kernel_size=[1, 1],\n",
    "        activation=NON_LINEAR)\n",
    "    drop2 = tf.layers.dropout(\n",
    "        inputs=conv3, rate=dr, training=(mode == learn.ModeKeys.TRAIN))\n",
    "    conv4 = tf.layers.conv2d(\n",
    "        inputs=drop2,\n",
    "        filters=256,\n",
    "        kernel_size=[1, 1],\n",
    "        activation=NON_LINEAR)\n",
    "    drop3 = tf.layers.dropout(\n",
    "        inputs=conv4, rate=dr, training=(mode == learn.ModeKeys.TRAIN))\n",
    "\n",
    "    # 1*78*1\n",
    "    conv5 = tf.layers.conv2d(\n",
    "        inputs=drop3,\n",
    "        filters=1,\n",
    "        kernel_size=[1, 1],\n",
    "        activation=NON_LINEAR)\n",
    "\n",
    "    # 1\n",
    "    logits_pt = tf.reduce_mean(\n",
    "        conv5, axis=[1, 2], name='GlobalAveragePooling')\n",
    "    #1 and 2 dimension is reduced to mean and return 1d array,length of array is batchsize\n",
    "\n",
    "    if 't' in stt:\n",
    "        # 1*78*TIMESPAN\n",
    "        conv5_trd = tf.layers.conv2d(\n",
    "            inputs=drop3,\n",
    "            filters=TIMESPAN,\n",
    "            kernel_size=[1, 1],\n",
    "            activation=NON_LINEAR)\n",
    "        # TIMESPAN\n",
    "        logits_trd = tf.reduce_mean(\n",
    "            conv5_trd, axis=[1, 2], name='GlobalAveragePooling')\n",
    "        logits_all['trd'] = logits_trd\n",
    "\n",
    "    if 'r' in stt:\n",
    "        # 1*78*RET_TIMESPAN\n",
    "        conv5_ret = tf.layers.conv2d(\n",
    "            inputs=drop3,\n",
    "            filters=RET_TIMESPAN,\n",
    "            kernel_size=[1, 1],\n",
    "            activation=NON_LINEAR)\n",
    "        # RET_TIMESPAN\n",
    "        logits_ret = tf.reduce_mean(\n",
    "            conv5_ret, axis=[1, 2], name='GlobalAveragePooling')\n",
    "        logits_all['ret'] = logits_ret\n",
    "\n",
    "    logits_all['pt'] = logits_pt\n",
    "    logits_all['emb'] = conv5\n",
    "    return logits_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d1c8c16bd7ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m np.load(\n\u001b[0;32m----> 2\u001b[0;31m         path.join('test_data', 'feat.npy'))\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 453\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.load(\n",
    "        path.join('test_data', 'feat.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from util import read_pickle, save_csv\n",
    "\n",
    "base_dir = Path('.')\n",
    "data_dir = base_dir.joinpath('data')\n",
    "mel_dir = base_dir.joinpath('mel_features')\n",
    "test_dir = base_dir.joinpath('test_data')\n",
    "\n",
    "# # save song id\n",
    "# song_id =  np.array([x.stem for x in mel_dir.iterdir()])\n",
    "# np.random.shuffle(song_id)\n",
    "# np.save(test_dir.joinpath('id.npy'), song_id)\n",
    "\n",
    "# mels = []\n",
    "# for song in song_id:\n",
    "#     mel = np.load(mel_dir.joinpath(f'{song}.npy'))\n",
    "#     mels.append(mel)\n",
    "# mels = np.concatenate(mels)\n",
    "# np.save(test_dir.joinpath('feat.npy'), mels)\n",
    "\n",
    "# song_id_sorted = np.load(test_dir.joinpath('id.npy'))\n",
    "\n",
    "# song_url_pop_unique = pd.read_csv(data_dir.joinpath(\"songs_url_pop-mandopop.tsv\"), sep='\\t')\n",
    "# pop_rank = []\n",
    "# for song in song_id_sorted:\n",
    "#     d = song_url_pop_unique[song_url_pop_unique['song_id']==song]\n",
    "#     pop_rank.append(d.popularity)\n",
    "# pop_rank = np.concatenate(pop_rank)\n",
    "# np.save(test_dir.joinpath('pop.npy'), pop_rank)\n",
    "song_url_pop_unique = pd.read_csv(data_dir.joinpath(\"songs_url_pop-mandopop.tsv\"), sep='\\t')\n",
    "feature = read_pickle(data_dir.joinpath(\"songs_genre-mandopop.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import save_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_rm = feature.drop(columns=['id', 'name','album_id','release_date']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>preview_url</th>\n",
       "      <th>popularity</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1i31BYKv1La3wVC6VbgGui</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/1a4604b2f86debd3...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.908</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-8.747</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.333</td>\n",
       "      <td>118.995</td>\n",
       "      <td>182040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77uwbOEaj6nMy6TlpEJg9Y</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/0eebe61274009d19...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.953</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.440</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.269</td>\n",
       "      <td>101.035</td>\n",
       "      <td>145173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5OR1Fbd7RSI18OoBVhgTAf</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/4fb6004d1b86271c...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.607</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-10.636</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.358</td>\n",
       "      <td>139.950</td>\n",
       "      <td>272973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7MmT3xzugKweEtethQiUeh</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/04b69da2b70636f7...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.844</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.645</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.398</td>\n",
       "      <td>106.028</td>\n",
       "      <td>220240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4vlzCpNsDFBaW99mrCGpmO</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/c948a6357454ce02...</td>\n",
       "      <td>39</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.614</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-10.513</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.559</td>\n",
       "      <td>174.089</td>\n",
       "      <td>222013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19DMSeSsfWaaUPNli1ojLi</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/0de61df8c6dd4388...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.515</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.020</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.756</td>\n",
       "      <td>98.142</td>\n",
       "      <td>169590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4GFhd6PIhuvnXoJdwFl4Gz</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/c5683c374cca6e8a...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.615</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.102</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.808</td>\n",
       "      <td>131.141</td>\n",
       "      <td>166620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4ggMtQb4qP53E0uSpeBOAN</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/d6ed0b113c89f52e...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.575</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.736</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.607</td>\n",
       "      <td>177.269</td>\n",
       "      <td>179690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0OVuhaotLVLmjuhoQYhRci</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/8ae49b91c1203b6d...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.912</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.473</td>\n",
       "      <td>0.0861</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.736</td>\n",
       "      <td>134.795</td>\n",
       "      <td>183023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>62wkedajcnKd8Thn8yHQNJ</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/7201a414b2ee19be...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.747</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.407</td>\n",
       "      <td>108.388</td>\n",
       "      <td>181003.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121794 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   song_id                                        preview_url  \\\n",
       "0   1i31BYKv1La3wVC6VbgGui  https://p.scdn.co/mp3-preview/1a4604b2f86debd3...   \n",
       "1   77uwbOEaj6nMy6TlpEJg9Y  https://p.scdn.co/mp3-preview/0eebe61274009d19...   \n",
       "2   5OR1Fbd7RSI18OoBVhgTAf  https://p.scdn.co/mp3-preview/4fb6004d1b86271c...   \n",
       "3   7MmT3xzugKweEtethQiUeh  https://p.scdn.co/mp3-preview/04b69da2b70636f7...   \n",
       "4   4vlzCpNsDFBaW99mrCGpmO  https://p.scdn.co/mp3-preview/c948a6357454ce02...   \n",
       "..                     ...                                                ...   \n",
       "11  19DMSeSsfWaaUPNli1ojLi  https://p.scdn.co/mp3-preview/0de61df8c6dd4388...   \n",
       "12  4GFhd6PIhuvnXoJdwFl4Gz  https://p.scdn.co/mp3-preview/c5683c374cca6e8a...   \n",
       "13  4ggMtQb4qP53E0uSpeBOAN  https://p.scdn.co/mp3-preview/d6ed0b113c89f52e...   \n",
       "14  0OVuhaotLVLmjuhoQYhRci  https://p.scdn.co/mp3-preview/8ae49b91c1203b6d...   \n",
       "15  62wkedajcnKd8Thn8yHQNJ  https://p.scdn.co/mp3-preview/7201a414b2ee19be...   \n",
       "\n",
       "    popularity  danceability  energy  key  loudness  speechiness  \\\n",
       "0           30         0.522   0.908  4.0    -8.747       0.0596   \n",
       "1           29         0.462   0.953  5.0    -6.440       0.1360   \n",
       "2           31         0.519   0.607  7.0   -10.636       0.0267   \n",
       "3           28         0.640   0.844  4.0    -9.645       0.0539   \n",
       "4           39         0.538   0.614  5.0   -10.513       0.1650   \n",
       "..         ...           ...     ...  ...       ...          ...   \n",
       "11           2         0.556   0.515  4.0    -5.020       0.0270   \n",
       "12           2         0.524   0.615  5.0    -5.102       0.0287   \n",
       "13           2         0.270   0.575  2.0    -5.736       0.0348   \n",
       "14           2         0.503   0.912  4.0    -4.473       0.0861   \n",
       "15           2         0.567   0.701  1.0    -5.747       0.0430   \n",
       "\n",
       "    acousticness  instrumentalness  liveness  valence    tempo  duration_ms  \n",
       "0       0.000171          0.002060     0.458    0.333  118.995     182040.0  \n",
       "1       0.002810          0.000000     0.424    0.269  101.035     145173.0  \n",
       "2       0.001830          0.000003     0.564    0.358  139.950     272973.0  \n",
       "3       0.039800          0.000005     0.122    0.398  106.028     220240.0  \n",
       "4       0.028000          0.005660     0.386    0.559  174.089     222013.0  \n",
       "..           ...               ...       ...      ...      ...          ...  \n",
       "11      0.826000          0.000000     0.105    0.756   98.142     169590.0  \n",
       "12      0.592000          0.000000     0.128    0.808  131.141     166620.0  \n",
       "13      0.511000          0.000002     0.187    0.607  177.269     179690.0  \n",
       "14      0.377000          0.000000     0.259    0.736  134.795     183023.0  \n",
       "15      0.548000          0.000000     0.114    0.407  108.388     181003.0  \n",
       "\n",
       "[121794 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_rm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>preview_url</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1i31BYKv1La3wVC6VbgGui</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/1a4604b2f86debd3...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77uwbOEaj6nMy6TlpEJg9Y</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/0eebe61274009d19...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5OR1Fbd7RSI18OoBVhgTAf</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/4fb6004d1b86271c...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7MmT3xzugKweEtethQiUeh</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/04b69da2b70636f7...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4vlzCpNsDFBaW99mrCGpmO</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/c948a6357454ce02...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92357</th>\n",
       "      <td>19DMSeSsfWaaUPNli1ojLi</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/0de61df8c6dd4388...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92358</th>\n",
       "      <td>4GFhd6PIhuvnXoJdwFl4Gz</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/c5683c374cca6e8a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92359</th>\n",
       "      <td>4ggMtQb4qP53E0uSpeBOAN</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/d6ed0b113c89f52e...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92360</th>\n",
       "      <td>0OVuhaotLVLmjuhoQYhRci</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/8ae49b91c1203b6d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92361</th>\n",
       "      <td>62wkedajcnKd8Thn8yHQNJ</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/7201a414b2ee19be...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92362 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      song_id  \\\n",
       "0      1i31BYKv1La3wVC6VbgGui   \n",
       "1      77uwbOEaj6nMy6TlpEJg9Y   \n",
       "2      5OR1Fbd7RSI18OoBVhgTAf   \n",
       "3      7MmT3xzugKweEtethQiUeh   \n",
       "4      4vlzCpNsDFBaW99mrCGpmO   \n",
       "...                       ...   \n",
       "92357  19DMSeSsfWaaUPNli1ojLi   \n",
       "92358  4GFhd6PIhuvnXoJdwFl4Gz   \n",
       "92359  4ggMtQb4qP53E0uSpeBOAN   \n",
       "92360  0OVuhaotLVLmjuhoQYhRci   \n",
       "92361  62wkedajcnKd8Thn8yHQNJ   \n",
       "\n",
       "                                             preview_url  popularity  \n",
       "0      https://p.scdn.co/mp3-preview/1a4604b2f86debd3...          30  \n",
       "1      https://p.scdn.co/mp3-preview/0eebe61274009d19...          29  \n",
       "2      https://p.scdn.co/mp3-preview/4fb6004d1b86271c...          31  \n",
       "3      https://p.scdn.co/mp3-preview/04b69da2b70636f7...          28  \n",
       "4      https://p.scdn.co/mp3-preview/c948a6357454ce02...          39  \n",
       "...                                                  ...         ...  \n",
       "92357  https://p.scdn.co/mp3-preview/0de61df8c6dd4388...           2  \n",
       "92358  https://p.scdn.co/mp3-preview/c5683c374cca6e8a...           2  \n",
       "92359  https://p.scdn.co/mp3-preview/d6ed0b113c89f52e...           2  \n",
       "92360  https://p.scdn.co/mp3-preview/8ae49b91c1203b6d...           2  \n",
       "92361  https://p.scdn.co/mp3-preview/7201a414b2ee19be...           2  \n",
       "\n",
       "[92362 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_url_pop_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_mandopop = song_url_pop_unique.merge(feature_rm,on=['song_id', 'preview_url', 'popularity'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(songs_mandopop, data_dir.joinpath('songs_mandopop.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(90, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
